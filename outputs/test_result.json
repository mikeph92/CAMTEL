{"task": "tumor", "testset": "pannuke", "augmented": "Yes", "method": "majorify vote", "num_tasks": 10, "Accuracy_test": 0.7717064619064331, "UAR_test": 0.618899405002594, "F1_test": 0.6896039247512817, "AUC_ROC_test": 0.7483437061309814}
{"task": "tumor", "testset": "pannuke", "augmented": "Yes", "method": "cluster based", "num_tasks": 10, "Accuracy_test": 0.7555612325668335, "UAR_test": 0.6777123212814331, "F1_test": 0.6944406628608704, "AUC_ROC_test": 0.8254008293151855}
{"task": "tumor", "testset": "ocelot", "augmented": "Yes", "method": "majorify vote", "num_tasks": 6, "Accuracy_test": 0.702924907207489, "UAR_test": 0.6097443699836731, "F1_test": 0.7253187298774719, "AUC_ROC_test": 0.740345299243927}
{"task": "tumor", "testset": "ocelot", "augmented": "Yes", "method": "cluster based", "num_tasks": 6, "Accuracy_test": 0.717313826084137, "UAR_test": 0.6593763828277588, "F1_test": 0.7500803470611572, "AUC_ROC_test": 0.8170644640922546}
{"task": "tumor", "testset": "nucls", "augmented": "Yes", "method": "majorify vote", "num_tasks": 6, "Accuracy_test": 0.790409505367279, "UAR_test": 0.8680212497711182, "F1_test": 0.7705014944076538, "AUC_ROC_test": 0.8027654886245728}
{"task": "tumor", "testset": "nucls", "augmented": "Yes", "method": "cluster based", "num_tasks": 6, "Accuracy_test": 0.7453240752220154, "UAR_test": 0.9015522003173828, "F1_test": 0.7416098713874817, "AUC_ROC_test": 0.8724123239517212}
{"task": "tumor", "testset": "pannuke", "augmented": "Yes", "method": "majorify vote", "num_tasks": 1, "Accuracy_test": 0.7398186922073364, "UAR_test": 0.6681767702102661, "F1_test": 0.6778987050056458, "AUC_ROC_test": 0.7288653254508972}
{"task": "tumor", "testset": "ocelot", "augmented": "Yes", "method": "majorify vote", "num_tasks": 1, "Accuracy_test": 0.6994324922561646, "UAR_test": 0.6137315034866333, "F1_test": 0.7242875099182129, "AUC_ROC_test": 0.7338492274284363}
{"task": "tumor", "testset": "nucls", "augmented": "Yes", "method": "majorify vote", "num_tasks": 1, "Accuracy_test": 0.7670489549636841, "UAR_test": 0.8981199860572815, "F1_test": 0.7575988173484802, "AUC_ROC_test": 0.7879157662391663}
{"task": "tumor", "testset": "ocelot", "augmented": "YesN", "method": "majorify vote", "num_tasks": 6, "Accuracy_test": 0.742082953453064, "UAR_test": 0.6927902102470398, "F1_test": 0.7755941152572632, "AUC_ROC_test": 0.7618957757949829}
{"task": "tumor", "testset": "ocelot", "augmented": "YesN", "method": "cluster based", "num_tasks": 6, "Accuracy_test": 0.7342023253440857, "UAR_test": 0.6793540716171265, "F1_test": 0.7668287754058838, "AUC_ROC_test": 0.8321055173873901}
{"task": "tumor", "testset": "nucls", "augmented": "YesN", "method": "majorify vote", "num_tasks": 6, "Accuracy_test": 0.8137699961662292, "UAR_test": 0.9336877465248108, "F1_test": 0.8025622963905334, "AUC_ROC_test": 0.8328514099121094}
{"task": "tumor", "testset": "nucls", "augmented": "YesN", "method": "cluster based", "num_tasks": 6, "Accuracy_test": 0.8148283362388611, "UAR_test": 0.8986566662788391, "F1_test": 0.797355055809021, "AUC_ROC_test": 0.9082238674163818}
{"task": "tumor", "testset": "pannuke", "augmented": "YesN", "method": "majorify vote", "num_tasks": 1, "Accuracy_test": 0.7559767961502075, "UAR_test": 0.7339591979980469, "F1_test": 0.7114413976669312, "AUC_ROC_test": 0.7526137232780457}
{"task": "tumor", "testset": "ocelot", "augmented": "YesN", "method": "majorify vote", "num_tasks": 1, "Accuracy_test": 0.7362928986549377, "UAR_test": 0.6889472603797913, "F1_test": 0.7707250118255615, "AUC_ROC_test": 0.755323052406311}
{"task": "tumor", "testset": "pannuke", "augmented": "YesN", "method": "majorify vote", "num_tasks": 10, "Accuracy_test": 0.7892531752586365, "UAR_test": 0.7286956310272217, "F1_test": 0.7391977906227112, "AUC_ROC_test": 0.7800033092498779}
{"task": "tumor", "testset": "pannuke", "augmented": "YesN", "method": "cluster based", "num_tasks": 10, "Accuracy_test": 0.7716871500015259, "UAR_test": 0.6746430993080139, "F1_test": 0.7077893614768982, "AUC_ROC_test": 0.8436198234558105}
{"task": "tumor", "testset": "nucls", "augmented": "YesN", "method": "majorify vote", "num_tasks": 1, "Accuracy_test": 0.830568790435791, "UAR_test": 0.8923434615135193, "F1_test": 0.8102493286132812, "AUC_ROC_test": 0.8403984904289246}
